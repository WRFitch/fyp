# Week 16

## TODO
- Create satellite inferrer and use this as the transferee for the GHG interpolator. 
- Import low- and high-resolution images into learner using the earth engine IDE. Start small and build up, buy more space if you need it. 
- Draft background study for write-up
- What benefits do an unproven inference provide? 

## DONE
#### Monday
- moved data ingress to Earth Engine's crappy web ide. It works now, but only just.
- Realised the satellite data is available in other places than just google earth engine and I didn't have to go through all this rubbish in the first place just because it's the first place I found it. Lesson learnt, I guess.

#### Tuesday
- subscribed to paperspace to simplify resource management.   
- Organised Allan Meeting
- Google earth engine actually does provide decent AI support in the form of google cloud AI platform. It's a paid service, but at this point I'm already paying for paperspace. Therefore, I've moved to using keras, google cloud AI/colab and tensorflow from fast.ai. This requires a certain level of commitment for me to finally knock out that fast.ai course as soon as possible. 
- Realised I only have about six weeks until the showcase, and ten weeks until my dissertation is due. Getting out 2000 words a week seems a realistic goal. 

#### Wednesday 
- Depression
- Found a decent tutorial and managed to complete a visualisation of satellite and methane datasets

#### Thursday 
- It might actually be a good idea to do a complete emissions profile all at once - the interpolation is projected to work by combining the knowledge of the satellite photography with low-resolution data informs high-resolution data. Combining a range of information sources may provide even more information for the interpolation
- Imported visualisation into parent script, with all datasets.

#### Friday
- culled datasets to the UK
- TODO investigate if tabular recommenders can be used to infer data from images.
  - there's an implication here of neural architectural combinatorics. How do you graft existing performant networks together into one larger network without losing functionality or efficiency? 

#### Saturday
- Sorted dataset import culling & relevant image scaling. 
- Training and testing strategy needs work
  - Datasets are disparately configured, meaning changes have to be propagated manually
  - Datasets are separate, when they could be columns in the same dataset that can be culled once, instead of... 12 times? 
- Finally imported some data into google drive. 
  - it's only data for london, which should be used to create a basic upscaler from fast.ai data. 
  - depending on performance, I could probably complete this independently of the neural training. Hooray, no streaming for me! 

## NOTES
- 2 possible training methods - random sampling and congruous areas
- There's no possible way of creating a complete set of high-resolution data without an absolutely obscene investment. However, it does allow on-the-fly calculation of GHG data at very precise locations, including looking at testing at discrete addresses. To verify this, we can also test against bilinear methods. 
- In terms of funding, there's that grant that was on HN today, and the uni has been generous in the past. Otherwise, crowdfunding may be an option?
- how do wind patterns affect my project?
- what are the issues with my data? how are these gases dispersed in the atmosphere? I'm mostly using total column values, but these values clearly aren't evenly dispersed. How can I ensure that these values are monitored at the ground level? Are there bands that monitor this? 
- look up the complexities of weather systems and how they might affect this. Ideally, the  NN would figure it out for me, but life is never that easy.
