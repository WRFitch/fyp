{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_model_testing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlL01n7dexnl"
      },
      "source": [
        "# Testing\n",
        "A notebook for testing an exported model. Ideally, this can be considered a part of a model evaluation pipeline, in which a model can be evaluated in greater depth.\n",
        "\n",
        "All notebooks in this project are to be considered development environments, rather than bona fide scripts that, when run, will produce the end product. Therefore, certain code blocks and documentation are added for developer convenience. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQzTgaA5fWu8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UDpJr3i-WS2"
      },
      "source": [
        "### Notebook Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX9MY-tjfCvL"
      },
      "source": [
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdaFWRYPe4Oc"
      },
      "source": [
        "from fastai.vision.all import *\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np \n",
        "import os \n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW2I5siTPGba"
      },
      "source": [
        "%rm -rf /content/fyp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEZzGW0Xeuty",
        "outputId": "ec94d52b-396a-4325-ec3a-1bb85feeb90e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import fyputil library\n",
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git\n",
        "%cd fyp/src/fyputil\n",
        "import constants as c\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'fyp'...\n",
            "remote: Enumerating objects: 380, done.\u001b[K\n",
            "remote: Counting objects: 100% (380/380), done.\u001b[K\n",
            "remote: Compressing objects: 100% (313/313), done.\u001b[K\n",
            "remote: Total 1351 (delta 258), reused 114 (delta 65), pack-reused 971\u001b[K\n",
            "Receiving objects: 100% (1351/1351), 171.77 MiB | 25.65 MiB/s, done.\n",
            "Resolving deltas: 100% (828/828), done.\n",
            "/content/fyp/src/fyputil\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKJFItks-ZXL"
      },
      "source": [
        "### Data Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3_RyVgmj4LI",
        "outputId": "2f3597e0-a9e5-4e71-f0a2-068da6151bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "err_headers = [c.lon, c.lat] + c.ghg_bands\n",
        "\n",
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "dnorm_ghg_df = pd.read_csv(c.ghg_csv)\n",
        "ghg_df = fyputil.normGhgDf(ghg_df)\n",
        "ghg_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>SO2_column_number_density</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>CH4_column_volume_mixing_ratio_dry_air</th>\n",
              "      <th>CO_column_number_density</th>\n",
              "      <th>tropospheric_HCHO_column_number_density</th>\n",
              "      <th>tropospheric_NO2_column_number_density</th>\n",
              "      <th>O3_column_number_density</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>47.938168</td>\n",
              "      <td>-0.795009</td>\n",
              "      <td>51.109648</td>\n",
              "      <td>10.531718</td>\n",
              "      <td>37.153821</td>\n",
              "      <td>9.913828</td>\n",
              "      <td>2.705834</td>\n",
              "      <td>6.081533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>43.566527</td>\n",
              "      <td>-0.786026</td>\n",
              "      <td>51.109648</td>\n",
              "      <td>10.337841</td>\n",
              "      <td>39.323846</td>\n",
              "      <td>12.108644</td>\n",
              "      <td>4.124599</td>\n",
              "      <td>6.106126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>46.108674</td>\n",
              "      <td>-0.777043</td>\n",
              "      <td>51.109648</td>\n",
              "      <td>8.525499</td>\n",
              "      <td>42.313591</td>\n",
              "      <td>12.558397</td>\n",
              "      <td>3.930123</td>\n",
              "      <td>4.485217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>47.704085</td>\n",
              "      <td>-0.768060</td>\n",
              "      <td>51.109648</td>\n",
              "      <td>7.223523</td>\n",
              "      <td>41.804573</td>\n",
              "      <td>14.744170</td>\n",
              "      <td>3.580968</td>\n",
              "      <td>1.337698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>51.427614</td>\n",
              "      <td>-0.759076</td>\n",
              "      <td>51.109648</td>\n",
              "      <td>8.900317</td>\n",
              "      <td>42.469231</td>\n",
              "      <td>19.928847</td>\n",
              "      <td>3.831177</td>\n",
              "      <td>0.821039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10792</th>\n",
              "      <td>10792</td>\n",
              "      <td>76.931755</td>\n",
              "      <td>0.363818</td>\n",
              "      <td>51.864233</td>\n",
              "      <td>78.159492</td>\n",
              "      <td>57.031807</td>\n",
              "      <td>47.757274</td>\n",
              "      <td>19.594411</td>\n",
              "      <td>98.302537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10793</th>\n",
              "      <td>10793</td>\n",
              "      <td>75.075876</td>\n",
              "      <td>0.372801</td>\n",
              "      <td>51.864233</td>\n",
              "      <td>75.768332</td>\n",
              "      <td>57.519190</td>\n",
              "      <td>40.399468</td>\n",
              "      <td>20.806978</td>\n",
              "      <td>94.711922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10794</th>\n",
              "      <td>10794</td>\n",
              "      <td>76.443141</td>\n",
              "      <td>0.381784</td>\n",
              "      <td>51.864233</td>\n",
              "      <td>79.216157</td>\n",
              "      <td>60.948625</td>\n",
              "      <td>40.913113</td>\n",
              "      <td>21.013862</td>\n",
              "      <td>95.276043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10795</th>\n",
              "      <td>10795</td>\n",
              "      <td>85.876993</td>\n",
              "      <td>0.390767</td>\n",
              "      <td>51.864233</td>\n",
              "      <td>77.271962</td>\n",
              "      <td>59.415460</td>\n",
              "      <td>35.553224</td>\n",
              "      <td>19.853508</td>\n",
              "      <td>94.502509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10796</th>\n",
              "      <td>10796</td>\n",
              "      <td>85.876993</td>\n",
              "      <td>0.399750</td>\n",
              "      <td>51.864233</td>\n",
              "      <td>77.271962</td>\n",
              "      <td>59.415460</td>\n",
              "      <td>35.553224</td>\n",
              "      <td>19.853508</td>\n",
              "      <td>94.502509</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10797 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...  O3_column_number_density\n",
              "0               0  ...                  6.081533\n",
              "1               1  ...                  6.106126\n",
              "2               2  ...                  4.485217\n",
              "3               3  ...                  1.337698\n",
              "4               4  ...                  0.821039\n",
              "...           ...  ...                       ...\n",
              "10792       10792  ...                 98.302537\n",
              "10793       10793  ...                 94.711922\n",
              "10794       10794  ...                 95.276043\n",
              "10795       10795  ...                 94.502509\n",
              "10796       10796  ...                 94.502509\n",
              "\n",
              "[10797 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8-jFzfG-OmN"
      },
      "source": [
        "### Selecting Optimal Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MSnKhta-Nyq"
      },
      "source": [
        "# move through each model in model_dir and find the one with the best RMSE. \n",
        "# As of 10/03/21, this is mrghg_060321-resnet152_increased_dataset_size_to_4k.pkl\n",
        "for root, _, files in os.walk(c.model_dir, topdown=True):\n",
        "    for name in files:\n",
        "      try:\n",
        "        full_path = os.path.join(root, name)\n",
        "        test_learner = load_learner(full_path)\n",
        "      except Exception:\n",
        "        print(Exception)\n",
        "        print(f\"model appears to have died. skipping... {full_path}\")\n",
        "        continue\n",
        "\n",
        "      print(full_path)\n",
        "      # Commented out because if it's unnecessarily run it'll take hours to complete. \n",
        "      # Only uncomment this if you have that time to spare. \n",
        "      # We're only testing 10% of the data, or otherwise we'll really be here all day. \n",
        "      #rmse = getModelRmse(test_learner, 10)\n",
        "      print(rmse)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH_gD0yfY7Od"
      },
      "source": [
        "### Get model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpBFOVFHK4Dn"
      },
      "source": [
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "def getModelRmse(model, modulus=1, err_df=None):\n",
        "  # Return a RMSE value for each GHG in the model's predicted values. \n",
        "  if err_df == None:\n",
        "    err_df = getErrs(model, ghg_df, modulus)\n",
        "\n",
        "  rtnval = []\n",
        "  for col in err_headers[2:]:\n",
        "    rtnval.append( math.sqrt( err_df[col].apply(lambda x:x**2) .mean()))\n",
        "  return rtnval\n",
        "\n",
        "def getPreds(model, ghg_df, modulus=1):\n",
        "  # Return a dataframe containing the model predictions from the given dataframe\n",
        "  pred_df = pd.DataFrame(columns=err_headers)\n",
        "  mod = 0\n",
        "  for idx, row in ghg_df.iterrows():\n",
        "    coords = (row.longitude, row.latitude)\n",
        "    if not fyputil.imgExported(coords): continue\n",
        "    if mod % modulus == 0 :\n",
        "      prediction = model.predict(fyputil.getFilepath(coords))[0]\n",
        "      pred_df.loc[len(pred_df)] = list(coords) + list(prediction)\n",
        "    mod += 1\n",
        "  return pred_df\n",
        "\n",
        "def getErrs(model, df, modulus=1, preds_df=None):\n",
        "  # Return a dataframe containing the difference between each prediction and the original value\n",
        "  if preds_df.empty:\n",
        "    preds_df = getPreds(model, df, modulus)\n",
        "  return getDiffs(preds_df, df)\n",
        "\n",
        "def getDiffs(pred_df, actual_df):\n",
        "  # Return a dataframe containing the differences between coordinate-indexed values in two dataframes. \n",
        "  diffs = pd.DataFrame(columns = err_headers)\n",
        "  for idx, row in pred_df.iterrows():\n",
        "    coords = (row.longitude, row.latitude)\n",
        "    # Keeping this in index lockstep would be an order of magnitude more efficient than this bodged lookup. \n",
        "    actual = fyputil.getValAt(coords, actual_df)[c.ghg_bands].squeeze()\n",
        "    prediction = row[2:]\n",
        "    if actual.empty: continue\n",
        "    differences = [pred - act for pred, act in zip(prediction, actual)]\n",
        "    diffs.loc[len(diffs)] = list(coords) + differences\n",
        "  return diffs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkO0TAvRRkDp"
      },
      "source": [
        "#model_name = c.model_name\n",
        "model_name = \"140321_add-normalisation_bs-128_trained-some-more\"\n",
        "best_model = load_learner(f\"{c.model_dir}/{model_name}.pkl\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry_Kep6n8uVN"
      },
      "source": [
        "valid_df = getModelRmse(best_model, 1000)\n",
        "valid_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M3T7taw9H50"
      },
      "source": [
        "preds = getPreds(best_model, ghg_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMEPx7LuPk48"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2XU5MWYXzf2"
      },
      "source": [
        "errs = getErrs(best_model, ghg_df, preds_df=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXGMKK37X5LT"
      },
      "source": [
        "errs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joYHfRZfGKiL"
      },
      "source": [
        "### Save model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skhnyQooGJlB"
      },
      "source": [
        "# Commented out so they aren't accidentally overwritten \n",
        "preds.to_csv(f\"{c.data_dir}/best_preds-{model_name}.csv\")\n",
        "errs.to_csv(f\"{c.data_dir}/pred_errs-{model_name}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYEzx2ykOlyn"
      },
      "source": [
        "### Retrieve model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDz1TDQnPw45"
      },
      "source": [
        "preds = pd.read_csv(f\"{c.data_dir}/best_preds-{model_name}.csv\")\n",
        "errs = pd.read_csv(f\"{c.data_dir}/pred_errs-{model_name}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Aj_cDhZA8g"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbTbgq-KZEjD"
      },
      "source": [
        "errs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xua-CHprfZK4"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCykJTyevfYZ"
      },
      "source": [
        "### Basic stat testing \n",
        "- Data exploration \n",
        "- RMSE per GHG\n",
        "- Extract outliers & view images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SzWvBN-0u8I"
      },
      "source": [
        "model_stats = pd.DataFrame(columns = [\"stat\"] + c.ghg_bands)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ychfb1HGCE_0"
      },
      "source": [
        "def getRmse(series): \n",
        "  return np.sqrt(np.mean(series**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flkVCRb-wghu"
      },
      "source": [
        "# Define aggregate metrics \n",
        "# TODO remove multiple iterations through errors, improve bigO \n",
        "means = [errs[ghg].mean() for ghg in c.ghg_bands ]\n",
        "stdevs = [errs[ghg].std() for ghg in c.ghg_bands ]\n",
        "rmse = [getRmse(errs[ghg]) for ghg in c.ghg_bands ]\n",
        "mae = [errs[ghg].abs().mean() for ghg in c.ghg_bands ]\n",
        "\n",
        "model_stats.loc[1] = [\"Mean\"] + means\n",
        "model_stats.loc[2] = [\"Standard Deviation\"] + stdevs \n",
        "model_stats.loc[3] = [\"RMSE\"] + rmse\n",
        "model_stats.loc[4] = [\"MAE\"] + mae\n",
        "\n",
        "model_stats[\"avg\"] = model_stats.mean(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUT_KzHcJPsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "29960025-86a9-4d70-d501-fb0cdcf4b6b8"
      },
      "source": [
        "model_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stat</th>\n",
              "      <th>CO_column_number_density</th>\n",
              "      <th>tropospheric_HCHO_column_number_density</th>\n",
              "      <th>tropospheric_NO2_column_number_density</th>\n",
              "      <th>O3_column_number_density</th>\n",
              "      <th>SO2_column_number_density</th>\n",
              "      <th>CH4_column_volume_mixing_ratio_dry_air</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mean</td>\n",
              "      <td>1.794107</td>\n",
              "      <td>-2.249522</td>\n",
              "      <td>-12.430723</td>\n",
              "      <td>-15.430360</td>\n",
              "      <td>6.025805</td>\n",
              "      <td>-11.210091</td>\n",
              "      <td>-5.583464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Standard Deviation</td>\n",
              "      <td>16.094458</td>\n",
              "      <td>14.553593</td>\n",
              "      <td>20.634910</td>\n",
              "      <td>17.543104</td>\n",
              "      <td>13.214439</td>\n",
              "      <td>16.556573</td>\n",
              "      <td>16.432846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RMSE</td>\n",
              "      <td>16.193394</td>\n",
              "      <td>14.725741</td>\n",
              "      <td>24.089048</td>\n",
              "      <td>23.362951</td>\n",
              "      <td>14.522921</td>\n",
              "      <td>19.994009</td>\n",
              "      <td>18.814677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MAE</td>\n",
              "      <td>12.932604</td>\n",
              "      <td>11.779999</td>\n",
              "      <td>16.725221</td>\n",
              "      <td>18.843600</td>\n",
              "      <td>11.788544</td>\n",
              "      <td>15.293509</td>\n",
              "      <td>14.560579</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 stat  ...        avg\n",
              "1                Mean  ...  -5.583464\n",
              "2  Standard Deviation  ...  16.432846\n",
              "3                RMSE  ...  18.814677\n",
              "4                 MAE  ...  14.560579\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb_aFC2_KZNZ"
      },
      "source": [
        "#### Plot raw stats "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ-XgtG1K62P"
      },
      "source": [
        "# Merge ghg and recalculate predictions \n",
        "errcols = [f\"{ghg}_err\" for ghg in c.ghg_bands]\n",
        "combi_df = ghg_df.merge(errs, how=\"inner\", on=[c.lon, c.lat], suffixes=(\"_orig\", \"_err\"))\n",
        "for ghg in c.ghg_bands:\n",
        "  combi_df[f\"{ghg}_pred\"] = combi_df[f\"{ghg}_orig\"] + combi_df[f\"{ghg}_err\"]\n",
        "\n",
        "combi_df[\"errsum\"] = combi_df[errcols].sum(axis=1)\n",
        "combi_df[\"errabs\"] = combi_df[errcols].abs().sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0qqFblRa8O"
      },
      "source": [
        "combi_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_nWYoAzKQdP"
      },
      "source": [
        "for ghg in c.ghg_bands:\n",
        "  combi_df.plot(x = f\"{ghg}_orig\", y = f\"{ghg}_pred\", kind = \"scatter\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljDXknEjKToW"
      },
      "source": [
        "### Find and process Outliers \n",
        "- Percentile \n",
        "  - 1.5*IQR for weak outliers\n",
        "  - 3*IQR for strong outliers\n",
        "- Linear regression \n",
        "- Standard deviation +- 2 (or 3) \n",
        "- Normal probability plot \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIG3A3uMGDLJ"
      },
      "source": [
        "# Individual outlier bands \n",
        "outliers = []\n",
        "for ghg in c.ghg_bands:\n",
        "  ghg_outliers = []\n",
        "  q1 = combi_df[f\"{ghg}_err\"].quantile(0.25)\n",
        "  q3 = combi_df[f\"{ghg}_err\"].quantile(0.75)\n",
        "  iqr = q3 - q1\n",
        "  lbound = q1 - 1.5*iqr\n",
        "  ubound = q3 + 1.5*iqr\n",
        "  ghg_outliers = combi_df.loc[(combi_df[f\"{ghg}_err\"] < lbound) | (combi_df[f\"{ghg}_err\"] > ubound)]\n",
        "  outliers.append(ghg_outliers)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9HVSLk4ituD"
      },
      "source": [
        "all_outliers = pd.concat(outliers, join=\"inner\").drop_duplicates()\n",
        "all_outliers[\"errsum\"] = all_outliers[errcols].abs().sum(axis=1)\n",
        "all_outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2quq1EoNiyDM"
      },
      "source": [
        "errcols = [f\"{ghg}_err\" for ghg in c.ghg_bands]\n",
        "multiple_outliers = pd.concat(outliers, join=\"inner\")\n",
        "multiple_outliers = multiple_outliers[multiple_outliers.duplicated()]\n",
        "multiple_outliers = multiple_outliers.drop_duplicates()\n",
        "multiple_outliers[\"errsum\"] = multiple_outliers[errcols].abs().sum(axis=1)\n",
        "multiple_outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9thV0DKwNfQ"
      },
      "source": [
        "multiple_outliers.nlargest(10, ['errsum'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg3PxSEWn6sI"
      },
      "source": [
        "# Show largest overpredictors \n",
        "for idx, row in combi_df.nlargest(50, ['errsum']).iterrows():\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ownRqYMd41HD"
      },
      "source": [
        "# show underpredictors\n",
        "for idx, row in combi_df.nsmallest(50, ['errsum']).iterrows():\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfxq5CzU6Z5y"
      },
      "source": [
        "# show best predictions \n",
        "for idx, row in combi_df.nsmallest(50, ['errabs']).iterrows():\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wOg6CkVfnnb"
      },
      "source": [
        "### Sample images vs predictions \n",
        "what regions are easier to predict than others? \n",
        "\n",
        "create accuracy heatmap "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udr8LN2Pfzg9"
      },
      "source": [
        "# Show outliers \n",
        "for idx, row in combi_df.nlargest(20, [f\"{c.SO2_band}_err\"]).iterrows():\n",
        "  if row[f\"{c.SO2_band}_pred\"] in [0, 100]: continue\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkT3UOLTbVC"
      },
      "source": [
        "###Testing against  other areas\n",
        "Export and test areas from a few different places\n",
        "- desert\n",
        "- tundra\n",
        "- creepy american robo-farms\n",
        "- other major cities\n",
        "  - manchester\n",
        "  - paris\n",
        "  - tokyo\n",
        "  - new york "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3ZjPe6iT_Qd"
      },
      "source": [
        "### Plot errors on folium heatmap "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYa-rhLsUFdd"
      },
      "source": [
        "###Experiment with facet implementation\n",
        "https://github.com/BCG-Gamma/facet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GshX7D6UhKj"
      },
      "source": [
        "### bicubic/linear/non-grid-based interpolation"
      ]
    }
  ]
}