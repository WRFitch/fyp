{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_model_testing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_model_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlL01n7dexnl"
      },
      "source": [
        "# Testing\n",
        "A notebook for testing an exported model. Ideally, this can be considered a part of a model evaluation pipeline, in which a model can be evaluated in greater depth.\n",
        "\n",
        "All notebooks in this project are to be considered development environments, rather than bona fide scripts that, when run, will produce the end product. Therefore, certain code blocks and documentation are added for developer convenience. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQzTgaA5fWu8"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UDpJr3i-WS2"
      },
      "source": [
        "### Notebook Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX9MY-tjfCvL"
      },
      "source": [
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qFXnfCTtc6f"
      },
      "source": [
        "from fastai.vision.all import *"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdaFWRYPe4Oc"
      },
      "source": [
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import os \n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW2I5siTPGba"
      },
      "source": [
        "# if we need to reimport the fyputil library after a runtime restart \n",
        "%rm -rf /content/fyp/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU-btmbttIpv"
      },
      "source": [
        "# Import fyputil library\n",
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEZzGW0Xeuty"
      },
      "source": [
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "# TODO refactor so utils are just called fyputil, aiutil, etc \n",
        "import fyp_utils as fyputil\n",
        "import ai_utils as aiutil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKJFItks-ZXL"
      },
      "source": [
        "### Data Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3_RyVgmj4LI"
      },
      "source": [
        "err_headers = [c.lon, c.lat] + c.ghg_bands\n",
        "\n",
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "dnorm_ghg_df = pd.read_csv(c.ghg_csv)\n",
        "ghg_df = fyputil.normGhgDf(ghg_df)\n",
        "\n",
        "# Defining this method so we can access the model\n",
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "model_name = \"140321_add-normalisation_bs-128_trained-some-more\"\n",
        "best_model = load_learner(f\"{c.model_dir}/{model_name}.pkl\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0NWM7089c2h"
      },
      "source": [
        "##Testing Optimal Model and Extracting Results \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8-jFzfG-OmN"
      },
      "source": [
        "### Selecting Optimal Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MSnKhta-Nyq"
      },
      "source": [
        "# move through each model in model_dir and find the one with the best RMSE. \n",
        "# As of 10/03/21, this is mrghg_060321-resnet152_increased_dataset_size_to_4k.pkl\n",
        "for root, _, files in os.walk(c.model_dir, topdown=True):\n",
        "    for name in files:\n",
        "      try:\n",
        "        full_path = os.path.join(root, name)\n",
        "        test_learner = load_learner(full_path)\n",
        "      except Exception:\n",
        "        print(Exception)\n",
        "        print(f\"model appears to have died. skipping... {full_path}\")\n",
        "        continue\n",
        "\n",
        "      print(full_path)\n",
        "      # Commented out because if it's unnecessarily run it'll take hours to complete. \n",
        "      # Only uncomment this if you have that time to spare. \n",
        "      # We're only testing 10% of the data, or otherwise we'll really be here all day. \n",
        "      #rmse = aiutil.getModelRmse(test_learner, 10)\n",
        "      print(rmse)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH_gD0yfY7Od"
      },
      "source": [
        "### Get model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry_Kep6n8uVN"
      },
      "source": [
        "valid_df = aiutil.getModelRmse(best_model, ghg_df, modulus=10000)\n",
        "valid_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M3T7taw9H50"
      },
      "source": [
        "preds = aiutil.getPreds(best_model, ghg_df, modulus = 10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMEPx7LuPk48"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2XU5MWYXzf2"
      },
      "source": [
        "errs = aiutil.getErrs(best_model, ghg_df, preds_df=preds, modulus = 10000)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXGMKK37X5LT"
      },
      "source": [
        "errs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joYHfRZfGKiL"
      },
      "source": [
        "### Save model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skhnyQooGJlB"
      },
      "source": [
        "# Commented out so they aren't accidentally overwritten \n",
        "preds.to_csv(f\"{c.data_dir}/best_preds-{model_name}.csv\")\n",
        "errs.to_csv(f\"{c.data_dir}/pred_errs-{model_name}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYEzx2ykOlyn"
      },
      "source": [
        "### Retrieve model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDz1TDQnPw45"
      },
      "source": [
        "preds = pd.read_csv(f\"{c.data_dir}/best_preds-{model_name}.csv\")\n",
        "errs = pd.read_csv(f\"{c.data_dir}/pred_errs-{model_name}.csv\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Aj_cDhZA8g"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbTbgq-KZEjD"
      },
      "source": [
        "errs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xua-CHprfZK4"
      },
      "source": [
        "## Stats Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCykJTyevfYZ"
      },
      "source": [
        "### Basic stat testing \n",
        "- Data exploration \n",
        "- RMSE per GHG\n",
        "- Extract outliers & view images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SzWvBN-0u8I"
      },
      "source": [
        "model_stats = pd.DataFrame(columns = [\"stat\"] + c.ghg_bands)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ychfb1HGCE_0"
      },
      "source": [
        "def getRmse(series): \n",
        "  return np.sqrt(np.mean(series**2))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flkVCRb-wghu"
      },
      "source": [
        "# Define aggregate metrics \n",
        "# TODO remove multiple iterations through errors, improve bigO \n",
        "means = [errs[ghg].mean() for ghg in c.ghg_bands ]\n",
        "stdevs = [errs[ghg].std() for ghg in c.ghg_bands ]\n",
        "rmse = [getRmse(errs[ghg]) for ghg in c.ghg_bands ]\n",
        "mae = [errs[ghg].abs().mean() for ghg in c.ghg_bands ]\n",
        "\n",
        "model_stats.loc[1] = [\"Mean\"] + means\n",
        "model_stats.loc[2] = [\"Standard Deviation\"] + stdevs \n",
        "model_stats.loc[3] = [\"RMSE\"] + rmse\n",
        "model_stats.loc[4] = [\"MAE\"] + mae\n",
        "\n",
        "model_stats[\"avg\"] = model_stats.mean(axis=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUT_KzHcJPsA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "2920edf1-aa93-4156-8117-539d53f7c74f"
      },
      "source": [
        "model_stats"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stat</th>\n",
              "      <th>CO_column_number_density</th>\n",
              "      <th>tropospheric_HCHO_column_number_density</th>\n",
              "      <th>tropospheric_NO2_column_number_density</th>\n",
              "      <th>O3_column_number_density</th>\n",
              "      <th>SO2_column_number_density</th>\n",
              "      <th>CH4_column_volume_mixing_ratio_dry_air</th>\n",
              "      <th>avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mean</td>\n",
              "      <td>0.501516</td>\n",
              "      <td>0.121305</td>\n",
              "      <td>0.646999</td>\n",
              "      <td>0.732723</td>\n",
              "      <td>-0.029718</td>\n",
              "      <td>0.705082</td>\n",
              "      <td>0.446318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Standard Deviation</td>\n",
              "      <td>9.479748</td>\n",
              "      <td>13.376465</td>\n",
              "      <td>8.390179</td>\n",
              "      <td>8.098189</td>\n",
              "      <td>12.141000</td>\n",
              "      <td>11.115444</td>\n",
              "      <td>10.433504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RMSE</td>\n",
              "      <td>9.492559</td>\n",
              "      <td>13.376385</td>\n",
              "      <td>8.414694</td>\n",
              "      <td>8.130890</td>\n",
              "      <td>12.140464</td>\n",
              "      <td>11.137261</td>\n",
              "      <td>10.448709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MAE</td>\n",
              "      <td>7.500864</td>\n",
              "      <td>10.542993</td>\n",
              "      <td>6.297513</td>\n",
              "      <td>6.022850</td>\n",
              "      <td>9.714386</td>\n",
              "      <td>8.507306</td>\n",
              "      <td>8.097652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 stat  ...        avg\n",
              "1                Mean  ...   0.446318\n",
              "2  Standard Deviation  ...  10.433504\n",
              "3                RMSE  ...  10.448709\n",
              "4                 MAE  ...   8.097652\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb_aFC2_KZNZ"
      },
      "source": [
        "#### Plot raw stats "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ-XgtG1K62P"
      },
      "source": [
        "# Merge ghg and recalculate predictions \n",
        "# wait, what did that comment mean? \n",
        "errcols = [f\"{ghg}_err\" for ghg in c.ghg_bands]\n",
        "combi_df = ghg_df.merge(errs, how=\"inner\", on=[c.lon, c.lat], suffixes=(\"_orig\", \"_err\"))\n",
        "for ghg in c.ghg_bands:\n",
        "  combi_df[f\"{ghg}_pred\"] = combi_df[f\"{ghg}_orig\"] + combi_df[f\"{ghg}_err\"]\n",
        "\n",
        "combi_df[\"errsum\"] = combi_df[errcols].sum(axis=1)\n",
        "combi_df[\"errabs\"] = combi_df[errcols].abs().sum(axis=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0qqFblRa8O"
      },
      "source": [
        "combi_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyY-I8S44T9Z"
      },
      "source": [
        "combi_df.to_csv(f\"{c.data_dir}/data_preds_errs-{model_name}.csv\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljDXknEjKToW"
      },
      "source": [
        "### Find and process Outliers \n",
        "- Percentile \n",
        "  - 1.5*IQR for weak outliers\n",
        "  - 3*IQR for strong outliers\n",
        "- Linear regression \n",
        "- Standard deviation +- 2 (or 3) \n",
        "- Normal probability plot \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIG3A3uMGDLJ"
      },
      "source": [
        "# Individual outlier bands \n",
        "outliers = []\n",
        "for ghg in c.ghg_bands:\n",
        "  ghg_outliers = []\n",
        "  q1 = combi_df[f\"{ghg}_err\"].quantile(0.25)\n",
        "  q3 = combi_df[f\"{ghg}_err\"].quantile(0.75)\n",
        "  iqr = q3 - q1\n",
        "  lbound = q1 - 1.5*iqr\n",
        "  ubound = q3 + 1.5*iqr\n",
        "  ghg_outliers = combi_df.loc[(combi_df[f\"{ghg}_err\"] < lbound) | (combi_df[f\"{ghg}_err\"] > ubound)]\n",
        "  outliers.append(ghg_outliers)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9HVSLk4ituD"
      },
      "source": [
        "all_outliers = pd.concat(outliers, join=\"inner\").drop_duplicates()\n",
        "all_outliers[\"errsum\"] = all_outliers[errcols].abs().sum(axis=1)\n",
        "all_outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2quq1EoNiyDM"
      },
      "source": [
        "errcols = [f\"{ghg}_err\" for ghg in c.ghg_bands]\n",
        "multiple_outliers = pd.concat(outliers, join=\"inner\")\n",
        "multiple_outliers = multiple_outliers[multiple_outliers.duplicated()]\n",
        "multiple_outliers = multiple_outliers.drop_duplicates()\n",
        "multiple_outliers[\"errsum\"] = multiple_outliers[errcols].abs().sum(axis=1)\n",
        "multiple_outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9thV0DKwNfQ"
      },
      "source": [
        "multiple_outliers.nlargest(10, ['errsum'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg3PxSEWn6sI"
      },
      "source": [
        "# Show largest overpredictors \n",
        "for idx, row in combi_df.nlargest(50, ['errsum']).iterrows():\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ownRqYMd41HD"
      },
      "source": [
        "# show underpredictors\n",
        "for idx, row in combi_df.nsmallest(50, ['errsum']).iterrows():\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfxq5CzU6Z5y"
      },
      "source": [
        "# show best predictions \n",
        "for idx, row in combi_df.nsmallest(50, ['errabs']).iterrows():\n",
        "  coords = (row[c.lon], row[c.lat])\n",
        "  print(coords)\n",
        "  print(row)\n",
        "  img_path = fyputil.getFilepath(coords)\n",
        "  display(Image.open(img_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkT3UOLTbVC"
      },
      "source": [
        "###Testing against  other areas\n",
        "Export and test areas from a few different places\n",
        "- desert\n",
        "- tundra\n",
        "- creepy american robo-farms\n",
        "- other major cities\n",
        "  - manchester\n",
        "  - paris\n",
        "  - tokyo\n",
        "  - new york "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3ZjPe6iT_Qd"
      },
      "source": [
        "### Plot errors on folium heatmap "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fPSN6bGz1yo"
      },
      "source": [
        "import ee\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "from folium.plugins import Fullscreen\n",
        "\n",
        "import json\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "%cd /content/fyp/src/fyputil\n",
        "import ee_constants as eec\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F7BA-T5ya70"
      },
      "source": [
        "abs_errs = errs.copy()\n",
        "for ghg in c.ghg_bands:\n",
        "  abs_errs[ghg] = abs_errs[ghg].apply(abs)\n",
        "abs_errs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJWlEkC0GXl3"
      },
      "source": [
        "errmap = folium.Map(\n",
        "    location = [51.5, 0.1], \n",
        "    prefer_canvas = True)\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles = eec.s2_id['tile_fetcher'].url_format,\n",
        "    attr = eec.map_attr,\n",
        "    overlay = True,\n",
        "    name = 'satellite photography median composite '\n",
        "  ).add_to(errmap)\n",
        "\n",
        "gradient = {0:'purple', 0.5:'blue', 0.6:'turquoise', 0.7:'lime', 0.8:'yellow', 0.9:'orange', 1:'red'}\n",
        "#gradient = eec.hmgrad_high\n",
        "\n",
        "for ghg in c.ghg_bands:\n",
        "  subset = abs_errs[[c.lat, c.lon, ghg]]\n",
        "  min = subset.min()[ghg]\n",
        "  mean = subset.mean()[ghg]\n",
        "  max = subset.max()[ghg]\n",
        "  folium.plugins.HeatMap(\n",
        "      data = subset.values,\n",
        "      name = f\"{ghg}_errs\",\n",
        "      show = False,\n",
        "      gradient = gradient, \n",
        "      min_opacity = 0.05\n",
        "  ).add_to(errmap)\n",
        "\n",
        "# Fullscreen functionality appears broken - perhaps it only works on chrome? \n",
        "Fullscreen().add_to(errmap)\n",
        "\n",
        "errmap.add_child(folium.LayerControl())\n",
        "\n",
        "# Image export doesn't seem to exist in Folium, so we'll take screenshots and \n",
        "# use them instead. Perhaps error stats could be included in the git repo and \n",
        "# incorporated into the demonstration notebook so people can view it for \n",
        "# themselves? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYa-rhLsUFdd"
      },
      "source": [
        "###Experiment with facet implementation\n",
        "https://github.com/BCG-Gamma/facet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GshX7D6UhKj"
      },
      "source": [
        "### bicubic/linear/non-grid-based interpolation"
      ]
    }
  ]
}