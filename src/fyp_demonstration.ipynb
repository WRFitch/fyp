{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_demonstration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_demonstration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahsw5_OPQumn"
      },
      "source": [
        "# FYP Demonstration\n",
        "### Will Fitch 1633241 \n",
        "### Brunel University Department of Computer Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmJhl_OmQuWk"
      },
      "source": [
        "This notebook is a demonstration of my final year project, in which I have used neural networks and transfer learning to infer greenhouse gas information from satellite data. You're going to need to [create a google earth engine account](https://signup.earthengine.google.com) if you want to export new image files. \n",
        "\n",
        "All notebooks in this project are to be considered development environments, rather than bona fide scripts that, when run, will produce the end product. Therefore, certain code blocks and documentation are added for developer convenience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZK3biQMnr0h"
      },
      "source": [
        "## Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uhTOvcXSsK4"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgKVSpGS2uvk"
      },
      "source": [
        "# Sometimes fastai doesn't want to play with colab, so we remove it and replace \n",
        "# it with a compliant version just to be sure. \n",
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLCg4aIuekFL"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPC4ECUh_uX6"
      },
      "source": [
        "import ee\n",
        "import folium\n",
        "import os\n",
        "import time\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from geopy.geocoders import Nominatim\n",
        "from google.colab import drive\n",
        "from IPython.display import Image\n",
        "from osgeo import gdal\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import fyputil library\n",
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "import ee_constants as eec\n",
        "import ee_utils as eeutil\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocIzW9a95oJd"
      },
      "source": [
        "#### Parts that don't require human input \n",
        "\n",
        "- Update `model_path` to point to wherever you've stored the pkl file for the model, since it can't be accessed using git because it's too big. However, it can be downloaded from the [latest github release](https://github.com/WRFitch/fyp)\n",
        "- Update `demo_dir` to point to wherever you're storing temp files while using this notebook. If you've mounted google drive, you can just create a file named \"demo_export\" in your google drive home folder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06_WJIskREEi"
      },
      "source": [
        "model_path = f\"{c.model_dir}/{c.model_name}.pkl\"\n",
        "demo_dir = f\"{c.drive_path}/demo_export\"\n",
        "\n",
        "fyp_path = \"/content/fyp\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBZQUFuy6AuH"
      },
      "source": [
        "# Initialise datasets\n",
        "origs = [f\"{band}_orig\" for band in c.ghg_bands]\n",
        "errs = [f\"{band}_err\" for band in c.ghg_bands]\n",
        "df = pd.read_csv(f\"{fyp_path}/datasets/data_preds_errs.csv\")\n",
        "ghg_df = pd.read_csv(f\"{fyp_path}/datasets/ghgs/ghgs.csv\")\n",
        "err_df[[c.lon, c.lat] + c.ghg_bands] = df[[c.lon, c.lat] + errs]\n",
        "norm_ghg_df = fyputil.normGhgDf(ghg_df.copy())\n",
        "\n",
        "# initialise nominatim client so we can get coords from postcode\n",
        "nominatim = Nominatim(user_agent=\"tutorial\") # TODO look up whether this user agent is fine. \n",
        "\n",
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "model = load_learner(model_path)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W-TcVdPnr0i"
      },
      "source": [
        "# Parses postcode into coordinates. You can put in anything else, like \"kenya\"\n",
        "def getCoordsFromString(s):\n",
        "  location = nominatim.geocode(s).raw\n",
        "  return (float(location['lon']), float(location['lat']))\n",
        "\n",
        "def getGhgsFromCoords(coords):\n",
        "  img_path = importImg(coords)\n",
        "  print(img_path)\n",
        "  ghgs = getGhgsFromImg(img_path)\n",
        "  # Currently these don't do anything\n",
        "  displayGhgs(ghgs)\n",
        "  displayHealthDefects(ghgs)\n",
        "  displayEnvEffects(ghgs)\n",
        "\n",
        "# use image pipeline to download an image based on a point object defined by the \n",
        "# given coordinates\n",
        "def importImg(coords):\n",
        "  # get a square from the given coordinates. \n",
        "  polygon = ee.Geometry.Point(coords).buffer(700).bounds()\n",
        "\n",
        "  name = f\"{coords[0]}_{coords[1]}\"\n",
        "  tifname = f\"{name}.tif\"\n",
        "\n",
        "  # check if image is cached before importing from GEE\n",
        "  cachePath = f\"{c.demo_dir}/{name}.png\"\n",
        "  if os.path.isfile(cachePath): \n",
        "    print(\"image for these coordinates has already been imported!\")\n",
        "    return cachePath\n",
        "\n",
        "  tifpath = f\"{demo_path}/{tifname}\"\n",
        "  if not os.path.isfile(tifpath):\n",
        "    print(f\"importing {tifname}\")\n",
        "    eeutil.exportGeotiff(eec.s2_img, polygon, 10, \"demo_export\", name)\n",
        "    \n",
        "    while not os.path.isfile(tifpath):\n",
        "      time.sleep(5)\n",
        "    print(f\"imported  {tifname}\")\n",
        "  \n",
        "  # Convert GeoTIFF to PNG.\n",
        "  fyputil.geotiffToPng(c.demo_dir, png_path=c.demo_dir)\n",
        "  fyputil.rmArtifact(f\"{demo_path}/{name}.png.aux.xml\")\n",
        "  print(f\"{tifpath} converted to PNG\")\n",
        "\n",
        "  importPath = f\"{demo_path}/{name}.png\"\n",
        "  if os.path.isfile(importPath): return importPath\n",
        "\n",
        "  print(\"image import failed\")\n",
        "\n",
        "def getGhgsFromImg(img_path):\n",
        "  print(\"getting GHG concentrations from given image\")\n",
        "  display(Image.open(img_path))\n",
        "  predictions = model.predict(img_path)[0]\n",
        "  dnorm_preds = fyputil.deNormPrediction(predictions, ghg_df)\n",
        "  return dnorm_preds \n",
        "\n",
        "def displayGhgs(ghgs):\n",
        "  print(ghgs)\n",
        "  # display ghgs as table\n",
        "  # compare against average\n",
        "  # display ghgs as a series of plots. \n",
        "  # for each ghg concentration, display health defects and mitigation strategies \n",
        "  # on table\n",
        "  # print table\n",
        "\n",
        "#def displayHealthDefects(ghgs):\n",
        "  # for each ghg, compare against concentration. Depending on how high they are,\n",
        "  # display the potential health effects and their likelihoods. \n",
        "  # return dict of ghg to string tuples of horrible effects and their likelihoods. \n",
        "\n",
        "#def displayEnvEffects(ghgs):\n",
        "  # for each ghg, compare against concentration. Depending on how high they are, \n",
        "  # display the potential environmental effects and their likelihoods. \n",
        "  # return dict of ghg to string tuples of horrible effects and their likelihoods. "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtlMLhOCnr0m"
      },
      "source": [
        "## Demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPKovmrQC0gk"
      },
      "source": [
        "### Greenhouse gas and model error prediction heatmaps\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qor1ZoorxbwM"
      },
      "source": [
        "# Show GHG map\n",
        "eec.map "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B7YWL8AUoLM"
      },
      "source": [
        "# Show Error Heatmap \n",
        "abs_errs = err_df.copy()\n",
        "for ghg in errs:\n",
        "  abs_errs[ghg] = abs_errs[ghg].apply(abs)\n",
        "\n",
        "errmap = eec.getErrMap(abs_errs)\n",
        "errmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0TyFGQzFkwb"
      },
      "source": [
        "### Model Interpolation\n",
        "\n",
        "Replace the \"postcode\" string with any string you like that pertains to a real geographic place; Nominatim can parse basically any location, since it uses OpenStreetMap. \n",
        "\n",
        "Currently these numbers arent contextualised but the final output is the greenhouse gas concentrations at this location, in the following order:  \n",
        "\n",
        "\n",
        "1.   Carbon Monoxide - mol/m^2\n",
        "2.   Formaldehyde - mol/m^2\n",
        "3.   Nitrogen Dioxide - mol/m^2\n",
        "4.   Ozone - mol/m^2\n",
        "5.   Sulphur Dioxide - mol/m^2\n",
        "6.   Methane - ppbV\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YxTpwXHsD-X"
      },
      "source": [
        "demo_coords = c.brunel_coords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsRXc1WRr4P9"
      },
      "source": [
        "postcode = \"UB8 3PH\"\n",
        "demo_coords = getCoordsFromString(postcode)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug7-OEUCQvVk"
      },
      "source": [
        "getGhgsFromCoords(demo_coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-cOHxUu262M"
      },
      "source": [
        "getGhgsFromCoords(getCoordsFromString(\"buckingham palace\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}