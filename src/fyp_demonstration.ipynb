{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_demonstration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_demonstration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahsw5_OPQumn"
      },
      "source": [
        "# FYP Demonstration\n",
        "### Will Fitch 1633241 \n",
        "### Brunel University Department of Computer Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmJhl_OmQuWk"
      },
      "source": [
        "This notebook is a demonstration of my final year project, in which I have used neural networks and transfer learning to infer greenhouse gas information from satellite data.\n",
        "\n",
        "All notebooks in this project are to be considered development environments, rather than bona fide scripts that, when run, will produce the end product. Therefore, certain code blocks and documentation are added for developer convenience"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZK3biQMnr0h"
      },
      "source": [
        "## Setup "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uhTOvcXSsK4"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgKVSpGS2uvk"
      },
      "source": [
        "# Sometimes fastai doesn't want to play with colab, so we remove it and replace \n",
        "# it with a compliant version just to be sure. \n",
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPC4ECUh_uX6"
      },
      "source": [
        "import ee\n",
        "import folium\n",
        "import os\n",
        "import time\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from geopy.geocoders import Nominatim\n",
        "from google.colab import drive\n",
        "from IPython.display import Image\n",
        "from osgeo import gdal\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import fyputil library\n",
        "# EE stuff needs initialising first\n",
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "import ee_constants as eec\n",
        "import ee_utils as eeutil\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocIzW9a95oJd"
      },
      "source": [
        "#### Parts that don't require human input "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBZQUFuy6AuH"
      },
      "source": [
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "demo_path = c.demo_dir\n",
        "model = load_learner(f\"{c.model_dir}/{c.model_name}.pkl\")\n",
        "\n",
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "norm_ghg_df = fyputil.normGhgDf(ghg_df)\n",
        "\n",
        "# initialise nominatim client so we can get coords from postcode\n",
        "nominatim = Nominatim(user_agent=\"tutorial\") # TODO look up whether this user agent is fine. "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W-TcVdPnr0i"
      },
      "source": [
        "# Parses postcode into coordinates. You can put in anything else, like \"kenya\"\n",
        "def getCoordinatesFromPostcode(postcode):\n",
        "  location = nominatim.geocode(postcode).raw\n",
        "  return (location['lon'], location['lat'])\n",
        "\n",
        "def getGhgsFromCoords(coords):\n",
        "  img_path = importImg(coords)\n",
        "  print(img_path)\n",
        "  ghgs = getGhgsFromImg(img_path)\n",
        "  displayGhgs(ghgs)\n",
        "  displayHealthDefects(ghgs)\n",
        "  displayEnvEffects(ghgs)\n",
        "\n",
        "# use image pipeline to download an image based on a point object defined by the \n",
        "# given coordinates\n",
        "def importImg(coords):\n",
        "  # get a square from the given image. \n",
        "  # TODO why is this buffer 500? the ideal pixel size should be 224, so 2240m. \n",
        "  polygon = ee.Geometry.Point(coords).buffer(700).bounds()\n",
        "\n",
        "  name = f\"{coords[0]}_{coords[1]}\"\n",
        "  tifname = f\"{name}.tif\"\n",
        "\n",
        "  # check if image is cached before importing from GEE\n",
        "  cachePath = f\"{demo_path}/{name}.png\"\n",
        "  if os.path.isfile(cachePath): \n",
        "    print(\"image for these coordinates has already been imported!\")\n",
        "    return cachePath\n",
        "\n",
        "  print(f\"importing {tifname}\")\n",
        "  eeutil.exportGeotiff(s2_img, polygon, 10, demo_dir, name)\n",
        "  tifpath = f\"{demo_path}/{tifname}\"\n",
        "  while not os.path.isfile(tifpath):\n",
        "    time.sleep(5)\n",
        "  print(f\"imported  {tifname}\")\n",
        "  \n",
        "  # Convert GeoTIFF to PNG.\n",
        "  fyputil.geotiffToPng(tifpath)\n",
        "  fyputil.rmArtifact(f\"{demo_path}/{name}.png.aux.xml\")\n",
        "  print(f\"{tifpath} converted to PNG\")\n",
        "\n",
        "  importPath = f\"{demo_path}/{name}.png\"\n",
        "  if os.path.isfile(importPath): return importPath\n",
        "\n",
        "  print(\"image import failed\")\n",
        "\n",
        "def getGhgsFromImg(img_path):\n",
        "  print(\"getting GHG concentrations from given image\")\n",
        "  display(Image.open(img_path))\n",
        "  predictions = model.predict(img_path)[0]\n",
        "  dnorm_preds = fyputil.deNormPrediction(predictions, ghg_df)\n",
        "  print(predictions)\n",
        "  return predictions \n",
        "\n",
        "def displayGhgs(ghgs):\n",
        "  print(ghgs)\n",
        "  # Add ghgs to table\n",
        "  # compare against average\n",
        "  # display ghgs as a series of plots. \n",
        "  # for each ghg concentration, display health defects and mitigation strategies \n",
        "  # on table\n",
        "  # print table\n",
        "\n",
        "def displayHealthDefects(ghgs):\n",
        "  print(ghgs)\n",
        "  # for each ghg, compare against concentration. Depending on how high they are,\n",
        "  # display the potential health effects and their likelihoods. \n",
        "  # return dict of ghg to string tuples of horrible effects and their likelihoods. \n",
        "\n",
        "def displayEnvEffects(ghgs):\n",
        "  print(ghgs)\n",
        "  # for each ghg, compare against concentration. Depending on how high they are, \n",
        "  # display the potential environmental effects and their likelihoods. \n",
        "  # return dict of ghg to string tuples of horrible effects and their likelihoods. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtlMLhOCnr0m"
      },
      "source": [
        "## Demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPKovmrQC0gk"
      },
      "source": [
        "### Visualisation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qor1ZoorxbwM"
      },
      "source": [
        "# TODO add error heatmaps\n",
        "eec.map "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0TyFGQzFkwb"
      },
      "source": [
        "### Model Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YxTpwXHsD-X"
      },
      "source": [
        "demo_coords = c.brunel_coords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsRXc1WRr4P9"
      },
      "source": [
        "# Replace this value with your intended postcode. \n",
        "postcode = \"UB8 3PH\"\n",
        "demo_coords = getCoordinatesFromPostcode(postcode):"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug7-OEUCQvVk"
      },
      "source": [
        "getGhgsFromCoords(demo_coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM32-YkPSMez"
      },
      "source": [
        "# Brunel Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq-YhuV_SOeD"
      },
      "source": [
        "brunel = (-0.47278354461716354, 51.53325658151181)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyr1b1ywSPnO"
      },
      "source": [
        "brunel_stats = model.predict(f\"{c.demo_dir}/-0.47278354461716354_51.53325658151181.png\")\n",
        "bpred = fyputil.deNormPrediction(brunel_stats[0], ghg_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfzXo7jvSPYL"
      },
      "source": [
        "# Not sure what this part does. \n",
        "for i in range(0, 6):\n",
        "  print(dnorm_ghg_df[c.ghg_bands[i]].quantile(0.5))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}