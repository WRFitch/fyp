{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_ai_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_ai_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rZJ0A7VHt1c"
      },
      "source": [
        "# AI Training\n",
        "\n",
        "This notebook exists to import and train new neural networks using fastai, based on the imported greenhouse gas/satellite photography dataset. \n",
        "\n",
        "All notebooks in this project are to be considered development environments, rather than bona fide scripts that, when run, will produce the end product. Therefore, certain code blocks and documentation are added for developer convenience. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQOjbqpH1R4"
      },
      "source": [
        "## Notebook Setup\n",
        "- Install & import necessary libraries\n",
        "- Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYo6jIv4H-8q"
      },
      "source": [
        "# Sometimes the colab fastai version can be wrong, so we reinstall with no cache\n",
        "# reinstalling, and restarting runtime should fix any major issues, including \n",
        "# CUDA OOM error\n",
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ONstZjIIOb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABLERMjyjhr"
      },
      "source": [
        "%rm -rf /content/fyp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnYH7qupPKfh"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAxIm8c-kPE"
      },
      "source": [
        "# Import fyputil library\n",
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbhrRqq98F6O"
      },
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMh7Ga0qm4NF"
      },
      "source": [
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "ghg_df = fyputil.normGhgDf(ghg_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFnm9ebP2vLB"
      },
      "source": [
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "def getCO(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)[0]\n",
        "\n",
        "# Wrapper around fyputil method to add ghg_df\n",
        "def imgIsInDf(path):\n",
        "  return fyputil.imgIsInDf(path, ghg_df)\n",
        "\n",
        "def getGhgImgs(path):\n",
        "  return get_image_files(path).filter(imgIsInDf)\n",
        "\n",
        "# TODO test this method\n",
        "def getGhgsFaster(img_path):\n",
        "  df = ghg_df\n",
        "  coords = getCoords(str(img_path))\n",
        "  ghgs = getValAt(coords, df).squeeze()\n",
        "  if ghgs.empty: return None\n",
        "  if None in ghgs: return None\n",
        "  return np.array(ghgs) # TODO parse this however needed\n",
        "\n",
        "# TODO implement multiple transforms pipeline\n",
        "# TODO revisit image normalisation\n",
        "# TODO ensure default random data splitter is ok (80/20 train/test split)\n",
        "mean,std = [0.5]*3,[0.5]*3\n",
        "mean,std = broadcast_vec(1, 4, mean, std)\n",
        "\n",
        "ghg_block = DataBlock(\n",
        "    blocks = (ImageBlock, RegressionBlock),\n",
        "    get_items = getGhgImgs,\n",
        "    get_y = getGhgsAsArr,\n",
        "    item_tfms = Resize(224),\n",
        "    batch_tfms = [Normalize.from_stats(mean,std)],\n",
        "    splitter  = RandomSplitter()\n",
        ")\n",
        "\n",
        "# Testing large batches to avoid overfitting and exploding gradients (though relu should sort this....)\n",
        "ghg_dl = ghg_block.dataloaders(c.big_png_dir, bs=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y1IUjc549dN"
      },
      "source": [
        "### Datablock/loader evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlAEUmnTYZUj"
      },
      "source": [
        "ghg_dl.show_batch(nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xEhWu99G3qP"
      },
      "source": [
        "ghg_block.summary(c.big_png_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPU6I-kssM6E"
      },
      "source": [
        "bigimgs = get_image_files(c.big_png_dir)\n",
        "len(bigimgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAAF2lbUSOrj"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRArNC3JDPD"
      },
      "source": [
        "### Image Recognition and Feature Extraction. \n",
        "\n",
        "- Train image-based predictor to guess greenhouse gas concentrations based on 1km square of land. \n",
        "  - Transfer an ImageNet predictor to work top-down\n",
        "  - Start by predicting one ghg and expand from there\n",
        "- Use image predictor to extract a basic feature set by slicing the network at different points. The idea is to limit the amount of data going into the tabular recommender, while transferring as much useful data as possible. We want to implicitly extract GHG-emitting features of each image without losing any detail, as a form of convolutional preprocessing. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpOjUXOVCXQs"
      },
      "source": [
        "# stats for training final network can be found in results/model/training_data.txt\n",
        "\n",
        "# TODO experiment with variable floating-point accuracy \n",
        "# TODO experiment with smaller networks\n",
        "# TODO experiment with batch normalisation\n",
        "# TODO experiment with adding a 2-layer head to the network to ensure decent conversions \n",
        "learn = cnn_learner(ghg_dl, resnet152, y_range=(0, 100), metrics=rmse)\n",
        "name = \"fresh learner\"\n",
        "learn.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIW8rDrf1bTC"
      },
      "source": [
        "learn.load(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjAg-nu2FwSw"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6IRAqLL_5Rf"
      },
      "source": [
        "# FROZEN\n",
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iUoIkzLxXtP"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTVVEMveecco"
      },
      "source": [
        "# UNFROZEN \n",
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwpwOiFRPpTt"
      },
      "source": [
        "# TODO When cutting release branch, update these to be the actual learning rates \n",
        "# used for training the final branch. \n",
        "lr = 0.0012"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxn_-fITxa_-"
      },
      "source": [
        "# Fit the first layer before unfreezing to get the network halfway there. If it \n",
        "# overfits for now, that's not really a problem. \n",
        "# This has been run twice to reach the given loss rates. \n",
        "learn.fit(4, 0.08) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vCjqYj49oh"
      },
      "source": [
        "learn.fit(4, 0.047863) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgvX4VAubfIA"
      },
      "source": [
        "learn.save(\"save1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgXrdXMKbl9K"
      },
      "source": [
        "learn.load(\"save1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32DR2wQyEv3Q"
      },
      "source": [
        "lrs = slice(0.003, 0.1)\n",
        "lrs2 = slice(1e-4, 1e-2)\n",
        "lrs3 = slice(1e-6, 1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3PJmsbYoZNr"
      },
      "source": [
        "learn.fit_one_cycle(5, max_lr=lrs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrdWxRA4C_mg"
      },
      "source": [
        "learn.fit_one_cycle(5, lrs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMVaCdY1G-QU"
      },
      "source": [
        "learn.fit_one_cycle(5, lrs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP3cjclvM2hE"
      },
      "source": [
        "learn.fit_one_cycle(5, lrs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN1PnrrPh6Vt"
      },
      "source": [
        "learn.fit(5, 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moVHcyAgRwso"
      },
      "source": [
        "learn.fit_one_cycle(5, lrs3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0jp_Yijk0d"
      },
      "source": [
        "learn.save(\"save2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flDEfEMxwuMe"
      },
      "source": [
        "learn.load(\"save2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LblgHV_wwq-M"
      },
      "source": [
        "learn.save(\"save3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C369lyjX0WDd"
      },
      "source": [
        "learn.load(\"save3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNPw3vYAMzEd"
      },
      "source": [
        "learn.save(\"save4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imQO7JrgR4PF"
      },
      "source": [
        "learn.load(\"save4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWMgznTpRuhE"
      },
      "source": [
        "learn.save(\"save5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75pJjnmzR6A5"
      },
      "source": [
        "learn.load(\"save5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMtIe4RUn3MP"
      },
      "source": [
        "learn.save(\"save6\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0imUay7OoHfl"
      },
      "source": [
        "learn.load(\"save6\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48OwUqVl4p9s"
      },
      "source": [
        "## Evaluate Model Performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAbHkA964t1i"
      },
      "source": [
        "### Plot results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkexw0M8hC5C"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEq6d1SGGGcQ"
      },
      "source": [
        "learn.show_results(ds_idx=10, dl=ghg_dl, nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vys7L7ICWjLI"
      },
      "source": [
        "# In-place testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLCPxb6FUgzv"
      },
      "source": [
        "import pandas as pd \n",
        "pred_df = pd.read_csv(f\"{c.data_dir}/CO_column_number_density.csv\")\n",
        "predcol = \"CO_pred\"\n",
        "pred_df[predcol] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW1aG_C2as28"
      },
      "source": [
        "spare = pred_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7t_7fH1XyJE"
      },
      "source": [
        "pred_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQn4RmgMbFFM"
      },
      "source": [
        "pred_df.iloc[1,5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTpgLoJXVQTw"
      },
      "source": [
        "for idx, row in pred_df.iterrows():\n",
        "  coords = (row.longitude, row.latitude)\n",
        "  if not fyputil.imgExported(coords): continue\n",
        "  filepath = fyputil.getFilepath(coords)\n",
        "  pred_df.iloc[idx, 5] = learn.predict(filepath)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHhouGQkWASF"
      },
      "source": [
        "pred_df[\"err\"] = pred_df[c.CO_band] - pred_df[predcol]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp6QVh89WgV6"
      },
      "source": [
        "rmse = math.sqrt(pred_df[\"err\"].apply(lambda x:x**2).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvgp7wOJXTW"
      },
      "source": [
        "### Export the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgqGJ_1m2Vu"
      },
      "source": [
        "# Export model so we can use it for other things. Note - this kills the model \n",
        "#TODO find better naming convention \n",
        "new_model = \"140321_add-normalisation_bs-128_trained-some-more\"\n",
        "learn.export(f\"{c.model_dir}/{new_model}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64mZBSinfzo"
      },
      "source": [
        "# Import model and test to see if it hasn't broken in the export process.\n",
        "imported_learner = load_learner(f\"{c.model_dir}/{c.model_name}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGYG53Pa_Qog"
      },
      "source": [
        "# Predict from imported learner\n",
        "imported_learner.predict(f\"{c.png_dir}/-0.73212695655741_51.2533785354393.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7193vyLfVy"
      },
      "source": [
        "#### Notes on Image Predictions\n",
        "\n",
        "A lower learning rate appears to cause slower training with more sophisticated conclusions. Sophistication also appears to arise from a deeper network.\n",
        "\n",
        "Effectively, this network recognises certain features of high-GHG land. Depending on sophistication, this may include airports, power plants, or other rare features, as well as recognising different types of wilderness or residential districts. This will be used to extract a feature set for a tabular recommender, which can then be used to find more accurate readings. "
      ]
    }
  ]
}