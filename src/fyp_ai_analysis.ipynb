{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_ai_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_ai_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rZJ0A7VHt1c"
      },
      "source": [
        "# AI data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQOjbqpH1R4"
      },
      "source": [
        "### Setup\n",
        "- Install & import necessary libraries\n",
        "- Mount drive\n",
        "- Import and define handy variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYo6jIv4H-8q"
      },
      "source": [
        "# Sometimes the colab fastai version can be wrong, so we reinstall with no cache\n",
        "# reinstalling, and restarting runtime should fix any major issues, including \n",
        "# CUDA OOM error\n",
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ONstZjIIOb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABLERMjyjhr"
      },
      "source": [
        "%rm -rf /content/fyp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnYH7qupPKfh"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAxIm8c-kPE"
      },
      "source": [
        "# Import fyputil library\n",
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbhrRqq98F6O"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMh7Ga0qm4NF"
      },
      "source": [
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "ghg_df = fyputil.normGhgDfProperly(ghg_df)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFnm9ebP2vLB"
      },
      "source": [
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "def imgIsInDf(path):\n",
        "  return fyputil.imgIsInDf(path, ghg_df)\n",
        "\n",
        "def getGhgImgs(path):\n",
        "  return get_image_files(path).filter(imgIsInDf)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h60VMitTdVL"
      },
      "source": [
        "# TODO implement multiple transforms pipeline\n",
        "# TODO revisit image normalisation\n",
        "# TODO ensure random data splitter is ok (it's not)\n",
        "\n",
        "ghg_block = DataBlock(\n",
        "    blocks = (ImageBlock, RegressionBlock),\n",
        "    get_items = getGhgImgs,\n",
        "    get_y = getGhgsAsArr,\n",
        "    item_tfms = Resize(460), \n",
        "    batch_tfms = aug_transforms(size=224, max_warp=0.05, max_zoom=1.0, max_rotate=45),\n",
        "    splitter  = RandomSplitter()\n",
        ")\n",
        "\n",
        "ghg_dl = ghg_block.dataloaders(c.big_png_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhlM7Gr71dWL"
      },
      "source": [
        "aug_transforms??"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlAEUmnTYZUj"
      },
      "source": [
        "ghg_dl.show_batch(nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xEhWu99G3qP"
      },
      "source": [
        "ghg_block.summary(c.big_png_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPU6I-kssM6E"
      },
      "source": [
        "bigimgs = get_image_files(c.big_png_dir)\n",
        "len(bigimgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAAF2lbUSOrj"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRArNC3JDPD"
      },
      "source": [
        "### Image Recognition and Feature Extraction. \n",
        "\n",
        "- Train image-based predictor to guess greenhouse gas concentrations based on 1km square of land. \n",
        "  - Transfer an ImageNet predictor to work top-down\n",
        "  - Start by predicting one ghg and expand from there\n",
        "- Use image predictor to extract a basic feature set by slicing the network at different points. The idea is to limit the amount of data going into the tabular recommender, while transferring as much useful data as possible. We want to implicitly extract GHG-emitting features of each image without losing any detail, as a form of convolutional preprocessing. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpOjUXOVCXQs"
      },
      "source": [
        "# TODO experiment with variable floating-point accuracy \n",
        "# TODO experiment with smaller networks\n",
        "# TODO experiment with batch normalisation\n",
        "# TODO experiment with adding a 2-layer head to the network to ensure decent conversions \n",
        "#learn = cnn_learner(ghg_dl, resnet152, y_range=(0, 100),  metrics=rmse).to_fp16()\n",
        "learn = cnn_learner(ghg_dl, resnet152, y_range=(0, 100),  metrics=rmse)\n",
        "name = \"fresh learner\"\n",
        "learn.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIW8rDrf1bTC"
      },
      "source": [
        "learn.load(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6IRAqLL_5Rf"
      },
      "source": [
        "# TODO examine 3d representation of problem space re: local optima \n",
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwpwOiFRPpTt"
      },
      "source": [
        "# TODO When cutting release branch, update these to be the actual learning rates used for training the final branch. \n",
        "# TODO experiment with different discriminative learning rates\n",
        "lr = 0.033"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjAg-nu2FwSw"
      },
      "source": [
        "learn.freeze()"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxn_-fITxa_-"
      },
      "source": [
        "# Fit the first layer before unfreezing to get the network halfway there. If it overfits for now, that's not really a problem. \n",
        "learn.fit(1, lr) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgvX4VAubfIA"
      },
      "source": [
        "# Saving mid-training, so I can figure out a decent training pathway\n",
        "learn.save(\"mid-training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgXrdXMKbl9K"
      },
      "source": [
        "learn.load(\"mid-training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iUoIkzLxXtP"
      },
      "source": [
        "learn.unfreeze()\n",
        "# Unfreeze the rest of the layers. How much do the rest of these layers need training? \n",
        "# Make sure to find new LRs. "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32DR2wQyEv3Q"
      },
      "source": [
        "lrs = slice(0.003, 0.1)\n",
        "lrs2 = slice(3e-4, 1e-3)\n",
        "lrs3 = slice(1e-6, 1e-3)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3PJmsbYoZNr"
      },
      "source": [
        "# TODO test fit_one_cycle - this may be better! it also includes discriminative lr slicing\n",
        "learn.fit_one_cycle(10, lr_max=lrs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0jp_Yijk0d"
      },
      "source": [
        "learn.save(\"fine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flDEfEMxwuMe"
      },
      "source": [
        "learn.load(\"fine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LblgHV_wwq-M"
      },
      "source": [
        "learn.save(\"xfine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C369lyjX0WDd"
      },
      "source": [
        "learn.load(\"xfine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48OwUqVl4p9s"
      },
      "source": [
        "## Evaluate Model Performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAbHkA964t1i"
      },
      "source": [
        "### Plot results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zkexw0M8hC5C"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEq6d1SGGGcQ"
      },
      "source": [
        "learn.show_results(ds_idx=4, dl=ghg_dl, nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDahQhrg4xue"
      },
      "source": [
        "### Plot model statistics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxXQG3N46wG0"
      },
      "source": [
        "#### Plot layer stats\n",
        "\n",
        "This allows us to see what the mean std and pct activation levels are, letting us see areas of the network that require further analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lghufP4W6pBO"
      },
      "source": [
        "learn.activation_stats.plot_layer_stats(151) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_kl2NRL8g0f"
      },
      "source": [
        "learn.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ia_ES349h3N"
      },
      "source": [
        "learn.activation_stats.color_dim(-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvgp7wOJXTW"
      },
      "source": [
        "### Export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzduW1MjOpKl"
      },
      "source": [
        "#### Cutting a neural encoder\n",
        "I hope this works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLDx2i_lOwlz"
      },
      "source": [
        "encoder = create_body(resnet152, cut = -2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhTyJVsnOtWB"
      },
      "source": [
        "#### Exporting main model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgqGJ_1m2Vu"
      },
      "source": [
        "# Export model so we can use it for other things. Note - this kills the model \n",
        "#TODO find better naming convention \n",
        "new_model = \"080321_resnet152_7k-imgs_fit-one-cycle\"\n",
        "learn.export(f\"{c.model_dir}/{new_model}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64mZBSinfzo"
      },
      "source": [
        "# Import model and test to see if it hasn't broken in the export process.\n",
        "imported_learner = load_learner(f\"{c.model_dir}/{c.model_name}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGYG53Pa_Qog"
      },
      "source": [
        "# Predict from imported learner\n",
        "imported_learner.predict(f\"{c.png_dir}/-0.73212695655741_51.2533785354393.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7193vyLfVy"
      },
      "source": [
        "#### Notes on Image Predictions\n",
        "\n",
        "A lower learning rate appears to cause slower training with more sophisticated conclusions. Sophistication also appears to arise from a deeper network, but I'm hitting a wall at roughly 0.6 rmse.\n",
        "\n",
        "Effectively, this network recognises certain features of high-GHG land. Depending on sophistication, this may include airports, power plants, or other rare features, as well as recognising different types of wilderness or residential districts. This will be used to extract a feature set for a tabular recommender, which can then be used to find more accurate readings. "
      ]
    }
  ]
}