{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_ai_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_ai_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rZJ0A7VHt1c"
      },
      "source": [
        "# AI data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQOjbqpH1R4"
      },
      "source": [
        "### Setup\n",
        "- Install & import necessary libraries\n",
        "- Mount drive\n",
        "- Import and define handy variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYo6jIv4H-8q"
      },
      "source": [
        "# Sometimes the colab fastai version can be wrong, so we reinstall with no cache\n",
        "# reinstalling, and restarting runtime should fix any major issues. \n",
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ONstZjIIOb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#from fastai import *\n",
        "#from fastai.vision import *\n",
        "from fastai.vision.all import *\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABLERMjyjhr"
      },
      "source": [
        "%rm -rf /content/fyp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnYH7qupPKfh"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAxIm8c-kPE"
      },
      "source": [
        "# Import fyputil library\n",
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwbX4M-B56Ks"
      },
      "source": [
        "#### Test Image Import\n",
        "\n",
        "(Not strictly necessary, but nice to have) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaakyRVgLP4a"
      },
      "source": [
        "# Import data from google drive \n",
        "# This is getting really slow. Is there too much data? If so, slice to only use \n",
        "# every tenth image so we still get a decently stratified set. \n",
        "#imgs = get_image_files(c.png_dir)\n",
        "#print(len(imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7--JJ1mEmoEZ"
      },
      "source": [
        "#big_imgs = get_image_files(big_png_dir)\n",
        "#print(len(big_imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbhrRqq98F6O"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMh7Ga0qm4NF"
      },
      "source": [
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "ghg_df = fyputil.normGhgDfProperly(ghg_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFnm9ebP2vLB"
      },
      "source": [
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "def getGhgImgs(path):\n",
        "  return get_image_files(path).filter(fyputil.imgIsInDf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h60VMitTdVL"
      },
      "source": [
        "# TODO implement multiple transforms pipeline\n",
        "# TODO revisit image normalisation\n",
        "\n",
        "ghg_block = DataBlock(\n",
        "    blocks = (ImageBlock, RegressionBlock),\n",
        "    get_items = getGhgImgs,\n",
        "    get_y = getGhgsAsArr,\n",
        "    item_tfms = Resize(224)\n",
        ")\n",
        "\n",
        "ghg_dl = ghg_block.dataloaders(c.big_png_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlAEUmnTYZUj"
      },
      "source": [
        "ghg_dl.show_batch(nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xEhWu99G3qP"
      },
      "source": [
        "ghg_block.summary(c.big_png_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAAF2lbUSOrj"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRArNC3JDPD"
      },
      "source": [
        "### Image Recognition and Feature Extraction. \n",
        "\n",
        "- Train image-based predictor to guess greenhouse gas concentrations based on 1km square of land. \n",
        "  - Transfer an ImageNet predictor to work top-down\n",
        "  - Start by predicting one ghg and expand from there\n",
        "- Use image predictor to extract a basic feature set by slicing the network at different points. The idea is to limit the amount of data going into the tabular recommender, while transferring as much useful data as possible. We want to implicitly extract GHG-emitting features of each image without losing any detail, as a form of convolutional preprocessing. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpOjUXOVCXQs"
      },
      "source": [
        "# uses a regression approach.\n",
        "# TODO analyse metrics. Really it doesn't seem to matter so long as everything \n",
        "#      is evaluated equally, but I'd like to be sure - ask Allan on Monday. \n",
        "# TODO Further experimentation with resnet size is necessary. 34 provides _ok_ \n",
        "#      predictions, longer is usually better but it takes longer to train. While\n",
        "#      I'm iterating on design, performance is necessary. Once I'm at a stage \n",
        "#      where I can export my model and use it as is, I'll take the time to train \n",
        "#      a much larger network. \n",
        "learn = cnn_learner(ghg_dl, resnet152, y_range=(0, 100),  metrics=rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJa47DDW1U-c"
      },
      "source": [
        "name = \"learner test\"\n",
        "learn.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIW8rDrf1bTC"
      },
      "source": [
        "learn.load(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6IRAqLL_5Rf"
      },
      "source": [
        "# TODO examine 3d representation of problem space re: local optima \n",
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwpwOiFRPpTt"
      },
      "source": [
        "lr = 0.05\n",
        "finelr = 0.0019\n",
        "xfinelr = 0.0001\n",
        "xxfinelr = 2e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd1q8otzr_Tw"
      },
      "source": [
        "# epochs = 5\n",
        "learn.fine_tune(2, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgvX4VAubfIA"
      },
      "source": [
        "# Saving mid-training, so I can figure out a decent training pathway\n",
        "learn.save(\"mid-training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgXrdXMKbl9K"
      },
      "source": [
        "learn.load(\"mid-training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM8OMzEmqUKk"
      },
      "source": [
        "learn.fine_tune(5, finelr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0jp_Yijk0d"
      },
      "source": [
        "learn.save(\"fine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3A1RlQ8jGGD"
      },
      "source": [
        "learn.fine_tune(5, xfinelr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LblgHV_wwq-M"
      },
      "source": [
        "learn.save(\"xfine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flDEfEMxwuMe"
      },
      "source": [
        "learn.load(\"xfine-tuning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYK-clRxsk2Y"
      },
      "source": [
        "# at this point, it doesn't seem to make any difference \n",
        "# There appears to be a point of diminishing returns, where rmse is just the \n",
        "# error rate of the given data. \n",
        "learn.fine_tune(10, xxfinelr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48OwUqVl4p9s"
      },
      "source": [
        "## Evaluate Model Performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAbHkA964t1i"
      },
      "source": [
        "### Plot results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEq6d1SGGGcQ"
      },
      "source": [
        "learn.show_results(ds_idx=1, dl=ghg_dl, nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7o2d5u2rtY"
      },
      "source": [
        "import fastai.utils.collect_env\n",
        "fastai.utils.collect_env.show_install(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KtKsvXv8JV5E",
        "outputId": "79b3e95e-4904-4b34-8fd2-d1666e118249"
      },
      "source": [
        "interp = Interpretation.from_learner(learn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDahQhrg4xue"
      },
      "source": [
        "### Plot model statistics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxXQG3N46wG0"
      },
      "source": [
        "#### Plot layer stats\n",
        "\n",
        "This allows us to see what the mean std and pct activation levels are, letting us see areas of the network that require further analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lghufP4W6pBO"
      },
      "source": [
        "learn.activation_stats.plot_layer_stats(151) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_kl2NRL8g0f"
      },
      "source": [
        "learn.recorder.plot_sched()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ia_ES349h3N"
      },
      "source": [
        "learn.activation_stats.color_dim(-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvgp7wOJXTW"
      },
      "source": [
        "### Export the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgqGJ_1m2Vu"
      },
      "source": [
        "# Export model so we can use it for other things\n",
        "# Note - this kills the model \n",
        "#TODO find better naming convention \n",
        "new_model = \"mrghg_230221_resnet34\"\n",
        "learn.export(f\"{c.model_dir}/{new_model}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64mZBSinfzo"
      },
      "source": [
        "# Import model and test to see if it hasn't broken in the export process.\n",
        "imported_learner = load_learner(f\"{c.model_dir}/{c.model_name}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGYG53Pa_Qog"
      },
      "source": [
        "# Predict from imported learner\n",
        "imported_learner.predict(f\"{c.png_dir}/-0.73212695655741_51.2533785354393.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7193vyLfVy"
      },
      "source": [
        "#### Notes on Image Predictions\n",
        "\n",
        "A lower learning rate appears to cause slower training with more sophisticated conclusions. Sophistication also appears to arise from a deeper network, but I'm hitting a wall at roughly 0.6 rmse.\n",
        "\n",
        "---\n",
        "\n",
        "Currently, the networks are having some trouble defining more subtle characteristics of the images, which shows some flaws in my work. The network will need some supplemental information to accurately predict the greenhouse gas at this point. This may include the following:\n",
        "- **Latitude/Longitude.** Geography may affect predictions - all the images in my current dataset are near London, meaning they have far more greenhouse gases than most places. To encode a knowledge of city geography into a neural net may take some work...\n",
        "- **Property Value.** How valuable is this land? This could go some way to encoding city dynamics, as well as explaining where the land might be. If land is rural, but valuable, it's likely to be near major cities or airports. \n",
        "- **Nearby GHG Values.** Combined with wind direction, an understanding of source & direction of airflow may describe how areas inherit ghg's from elsewhere. An example of this would be the high concentration of NO<sub>2</sub> north of Heathrow Airport, which may be caused by common flight patterns heading north. \n",
        "- **Wind Direction.** See above. \n",
        "- **Land Use.** Depending on detail, this may help alleviate the \"grey field/massive factory\" issue described in my log. By proving that certain areas are rural, residential, or industrial, we can limit errors based on inferring purely visual information. If we can specifically define what a large grey box is doing, we can also come to more developed conclusions about its purpose. A recycling center, an oil refinery, and a brewery may all look similar from above, but information about what they _are_ will limit a neural network getting confused. \n",
        "- **Population Density/Economic Output.** This will work in a similar way to property value, where we can predict human activity and its effects on greenhouse gases. Economic output may have a complex relationship to GHG emissions that cannot be easily represented, depending on the form of industry. For example, an eco-tourist attraction may rely on its low carbon footprint for survival, whereas a petrol station relies on high carbon ouput. \n",
        "- **Land Height**\n",
        "\n",
        "Effectively, this network recognises certain features of high-GHG land. Depending on sophistication, this may include airports, power plants, or other rare features, as well as recognising different types of wilderness or residential districts. This will be used to extract a feature set for a tabular recommender, which can then be used to find more accurate readings. "
      ]
    }
  ]
}