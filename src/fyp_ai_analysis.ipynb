{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fyp_ai_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WRFitch/fyp/blob/main/src/fyp_ai_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rZJ0A7VHt1c"
      },
      "source": [
        "# AI data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQOjbqpH1R4"
      },
      "source": [
        "### Setup\n",
        "- Install & import necessary libraries\n",
        "- Mount drive\n",
        "- Import and define handy variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYo6jIv4H-8q"
      },
      "source": [
        "# Sometimes the colab fastai version can be wrong, so we reinstall with no cache\n",
        "# uninstalling, reinstalling, and restarting runtime should fix any major issues. \n",
        "!pip uninstall -y fastai\n",
        "!pip install -U --no-cache-dir fastai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-ONstZjIIOb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f34f51-f61c-459d-b77a-c4ea40a34d8a"
      },
      "source": [
        "# TODO clean up imports - I can't seriously need all this\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from fastai import *\n",
        "from fastai.callback.hook import * \n",
        "from fastai.tabular import *\n",
        "from fastai.vision import *\n",
        "from fastai.vision.all import *\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABLERMjyjhr"
      },
      "source": [
        "%rm -rf /content/fyp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnYH7qupPKfh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81810d5f-8bd5-47c0-b601-f75284eca22d"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/WRFitch/fyp.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'fyp'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 999 (delta 15), reused 0 (delta 0), pack-reused 971\u001b[K\n",
            "Receiving objects: 100% (999/999), 166.68 MiB | 39.42 MiB/s, done.\n",
            "Resolving deltas: 100% (585/585), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAxIm8c-kPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00819054-7df2-4d00-a8c7-fe832729e4d1"
      },
      "source": [
        "# Import fyputil library\n",
        "%cd /content/fyp/src/fyputil\n",
        "import constants as c\n",
        "import fyp_utils as fyputil\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fyp/src/fyputil\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIzshMBG1_O7"
      },
      "source": [
        "drive_path = \"/content/drive/MyDrive/\"\n",
        "png_dir = c.png_dir\n",
        "model_dir = c.model_dir\n",
        "tfm_dir = f\"{c.data_dir}/png_tfms\"\n",
        "big_png_dir = f\"{c.data_dir}/png_224\"\n",
        "big_tfm_dir = f\"{c.data_dir}/224_png_tfms\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwbX4M-B56Ks"
      },
      "source": [
        "#### Test Image Import\n",
        "\n",
        "(Not strictly necessary, but nice to have) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaakyRVgLP4a"
      },
      "source": [
        "# Import data from google drive \n",
        "# This is getting really slow. Is there too much data? If so, slice to only use \n",
        "# every tenth image so we still get a decently stratified set. \n",
        "#imgs = get_image_files(c.png_dir)\n",
        "#print(len(imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7--JJ1mEmoEZ"
      },
      "source": [
        "#big_imgs = get_image_files(big_png_dir)\n",
        "#print(len(big_imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHXoqcVXEvAo"
      },
      "source": [
        "#tfm_imgs = get_image_files(tfm_dir)\n",
        "#print(len(tfm_imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hepWCn1esacF"
      },
      "source": [
        "big_tfms = get_image_files(big_tfm_dir)\n",
        "len(big_tfms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbhrRqq98F6O"
      },
      "source": [
        "### Data Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBeSobsZjdPE"
      },
      "source": [
        "#### Sort Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndLf6Glt8JoL"
      },
      "source": [
        "# Parse CSVs into pandas dataframes\n",
        "# TODO rewrite so we aren't deleting columns directly - do it properly! Incorporate these into one csv export in the \n",
        "#      output pipeline \n",
        "co_df = pd.read_csv(f\"{c.data_dir}/{c.CO_band}.csv\")\n",
        "del co_df[\".geo\"]\n",
        "hcho_df = pd.read_csv(f\"{c.data_dir}/{c.HCHO_band}.csv\")\n",
        "del hcho_df[\".geo\"]\n",
        "no2_df = pd.read_csv(f\"{c.data_dir}/{c.NO2_band}.csv\")\n",
        "del no2_df[\".geo\"]\n",
        "o3_df = pd.read_csv(f\"{c.data_dir}/{c.O3_band}.csv\")\n",
        "del o3_df[\".geo\"]\n",
        "so2_df = pd.read_csv(f\"{c.data_dir}/{c.SO2_band}.csv\")\n",
        "del so2_df[\".geo\"]\n",
        "ch4_df = pd.read_csv(f\"{c.data_dir}/{c.CH4_band}.csv\")\n",
        "del ch4_df[\".geo\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A-nIhUALDxx"
      },
      "source": [
        "# Incorporate individual csvs into one ghg dataframe. Badly. \n",
        "# TODO fix this so we aren't repeating the same thing over and over\n",
        "mrg_params = [c.lon, c.lat, 'system:index']\n",
        "# somehow this means \"intersect\". We're taking the intersect so we know we have common values. \n",
        "mrg_type = 'inner'\n",
        "\n",
        "intersect = pd.merge(so2_df, ch4_df, how=mrg_type, on=mrg_params)\n",
        "intersect = pd.merge(intersect, co_df, how=mrg_type, on=mrg_params)\n",
        "intersect = pd.merge(intersect, hcho_df, how=mrg_type, on=mrg_params)\n",
        "intersect = pd.merge(intersect, no2_df, how=mrg_type, on=mrg_params)\n",
        "intersect = pd.merge(intersect, o3_df, how=mrg_type, on=mrg_params)\n",
        "\n",
        "print(intersect.shape)\n",
        "intersect.iloc[0:4] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e7dwjykV6kr"
      },
      "source": [
        "raw_ghg_df = intersect.copy()\n",
        "\n",
        "for index, row in intersect.iterrows():\n",
        "  coords = (row.longitude, row.latitude)\n",
        "  #print(coords)\n",
        "  if not fyputil.imgExported(coords):\n",
        "    #print(f\"dropping {fyputil.getFilepath(coords)} from row {index}\")\n",
        "    # TODO implement this in a way that doesn't recreate the dataframe thousands of times\n",
        "    raw_ghg_df = raw_ghg_df.drop(index=index)\n",
        "\n",
        "# Normalise ghg numbers so they can be more easily predicted by the network, and \n",
        "# fit into a consistent, normalised y_range \n",
        "ghg_df = raw_ghg_df.copy()\n",
        "ghg_df = fyputil.normGhgDfProperly(ghg_df)\n",
        "\n",
        "print(intersect.shape)\n",
        "print(raw_ghg_df.shape)\n",
        "raw_ghg_df.iloc[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ulO_e2A4r53"
      },
      "source": [
        "ghg_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomEwhrhgmIk"
      },
      "source": [
        "ghg_df.to_csv(f\"{c.data_dir}/good_ghg.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhEryKp8hd7q"
      },
      "source": [
        "def copyUsableImages():\n",
        "  for idx, row in ghg_df.iterrows():\n",
        "    coords = (row.longitude, row.latitude)\n",
        "    filename = fyputil.getFilepath(coords)\n",
        "    os.system(f\"cp {filename} {c.data_dir}/png_tfms/orig/normal/{row.longitude}_{row.latitude}\")\n",
        "    print(idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GribG3uuqWI"
      },
      "source": [
        "#### Sort dataframes in a way that's far easier\n",
        "THIS IS THE ONLY PART THAT'S NECESSARY FOR THE CURRENT TRAINING PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMh7Ga0qm4NF"
      },
      "source": [
        "ghg_df = pd.read_csv(c.ghg_csv)\n",
        "ghg_df = fyputil.normGhgDfProperly(ghg_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0RscteJjihg"
      },
      "source": [
        "#### Sort Data Import Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFnm9ebP2vLB"
      },
      "source": [
        "def getGhgsAsArr(img_path):\n",
        "  return fyputil.getGhgsAsArr(img_path, ghg_df)\n",
        "\n",
        "#def imgIsInDf(img_path):\n",
        "#  # Probably a faster way to do this\n",
        "#  val = fyputil.getGhgs(img_path, ghg_df)\n",
        "#  if val == None: return False \n",
        "#  if len(val) == 6: return True \n",
        "#  return False\n",
        "\n",
        "def getGhgImgs(path):\n",
        "  return get_image_files(path).filter(fyputil.imgIsInDf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRXxcc1rFvR2"
      },
      "source": [
        "# Look for any duplicated files and remove \n",
        "count = 0\n",
        "for root, dir, files in os.walk(big_tfm_dir):\n",
        "  for file in files:\n",
        "    if \"(\" in file:\n",
        "      print(f\"{root}/{file}\")\n",
        "      os.remove(f\"{root}/{file}\")\n",
        "      count += 1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ga_1VNoipF"
      },
      "source": [
        "### Create DataBlocks for training the model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s6-BbIw5ciF"
      },
      "source": [
        "#### Standard GHG Block\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h60VMitTdVL"
      },
      "source": [
        "# TODO implement multiple transforms pipeline\n",
        "# TODO revisit image normalisation\n",
        "\n",
        "ghg_block = DataBlock(\n",
        "    blocks = (ImageBlock, RegressionBlock),\n",
        "    get_items = getGhgImgs,\n",
        "    get_y = getGhgsAsArr,\n",
        "    item_tfms = Resize(224)\n",
        ")\n",
        "\n",
        "ghg_dl = ghg_block.dataloaders(big_png_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlAEUmnTYZUj"
      },
      "source": [
        "ghg_dl.show_batch(nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xEhWu99G3qP"
      },
      "source": [
        "ghg_block.summary(big_png_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAAF2lbUSOrj"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRArNC3JDPD"
      },
      "source": [
        "### Image Recognition and Feature Extraction. \n",
        "\n",
        "- Train image-based predictor to guess greenhouse gas concentrations based on 1km square of land. \n",
        "  - Transfer an ImageNet predictor to work top-down\n",
        "  - Start by predicting one ghg and expand from there\n",
        "- Use image predictor to extract a basic feature set by slicing the network at different points. The idea is to limit the amount of data going into the tabular recommender, while transferring as much useful data as possible. We want to implicitly extract GHG-emitting features of each image without losing any detail, as a form of convolutional preprocessing. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpOjUXOVCXQs"
      },
      "source": [
        "# uses a regression approach.\n",
        "# TODO analyse metrics. Really it doesn't seem to matter so long as everything \n",
        "#      is evaluated equally, but I'd like to be sure - ask Allan on Monday. \n",
        "# TODO Further experimentation with resnet size is necessary. 34 provides _ok_ \n",
        "#      predictions, longer is usually better but it takes longer to train. While\n",
        "#      I'm iterating on design, performance is necessary. Once I'm at a stage \n",
        "#      where I can export my model and use it as is, I'll take the time to train \n",
        "#      a much larger network. \n",
        "learn = cnn_learner(ghg_dl, resnet152, y_range=(0, 100),  metrics=rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJa47DDW1U-c",
        "outputId": "1b583baf-8ef5-4781-fafd-5ed0f677b4df"
      },
      "source": [
        "name = \"learner test\"\n",
        "learn.save(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/learner test.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIW8rDrf1bTC",
        "outputId": "15d3b04f-3c04-49b0-aca3-afc5242770ae"
      },
      "source": [
        "learn.load(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f788818f588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6IRAqLL_5Rf"
      },
      "source": [
        "# TODO examine 3d representation of problem space re: local optima \n",
        "learn.lr_find()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwpwOiFRPpTt"
      },
      "source": [
        "lr = 0.05\n",
        "finelr = 0.0019\n",
        "xfinelr = 0.0001\n",
        "xxfinelr = 2e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd1q8otzr_Tw"
      },
      "source": [
        "# epochs = 5\n",
        "learn.fine_tune(2, lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgvX4VAubfIA",
        "outputId": "b939283e-e907-4c17-9e5f-079d507ad0af"
      },
      "source": [
        "# Saving mid-training, so I can figure out a decent training pathway\n",
        "learn.save(\"mid-training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/mid-training.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgXrdXMKbl9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ec149c-f089-49db-c10b-ec113796c807"
      },
      "source": [
        "learn.load(\"mid-training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f7888647748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM8OMzEmqUKk"
      },
      "source": [
        "learn.fine_tune(5, finelr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM0jp_Yijk0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61780854-f86b-4cc5-fa78-ec2128d49fd0"
      },
      "source": [
        "learn.save(\"fine-tuning\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/fine-tuning.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3A1RlQ8jGGD"
      },
      "source": [
        "learn.fine_tune(5, xfinelr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LblgHV_wwq-M",
        "outputId": "94b2d5a3-9c9b-4f55-a0bc-c0e9a57ee3a9"
      },
      "source": [
        "learn.save(\"xfine-tuning\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('models/xfine-tuning.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flDEfEMxwuMe",
        "outputId": "1dbc6495-09ed-4b42-8386-9f82b6b6c66e"
      },
      "source": [
        "learn.load(\"xfine-tuning\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.learner.Learner at 0x7f2c1c642a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYK-clRxsk2Y"
      },
      "source": [
        "# at this point, it doesn't seem to make any difference \n",
        "# There appears to be a point of diminishing returns, where rmse is just the \n",
        "# error rate of the given data. \n",
        "learn.fine_tune(10, xxfinelr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48OwUqVl4p9s"
      },
      "source": [
        "## Evaluate Model Performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAbHkA964t1i"
      },
      "source": [
        "### Plot results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEq6d1SGGGcQ"
      },
      "source": [
        "learn.show_results(ds_idx=1, dl=ghg_dl, nrows=9, max_n=9, figsize = (50,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7o2d5u2rtY"
      },
      "source": [
        "import fastai.utils.collect_env\n",
        "fastai.utils.collect_env.show_install(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KtKsvXv8JV5E",
        "outputId": "79b3e95e-4904-4b34-8fd2-d1666e118249"
      },
      "source": [
        "interp = Interpretation.from_learner(learn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDahQhrg4xue"
      },
      "source": [
        "### Plot model statistics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxXQG3N46wG0"
      },
      "source": [
        "#### Plot layer stats\n",
        "\n",
        "This allows us to see what the mean std and pct activation levels are, letting us see areas of the network that require further analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lghufP4W6pBO"
      },
      "source": [
        "learn.activation_stats.plot_layer_stats(151) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_kl2NRL8g0f"
      },
      "source": [
        "learn.recorder.plot_sched()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ia_ES349h3N"
      },
      "source": [
        "learn.activation_stats.color_dim(-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asvgp7wOJXTW"
      },
      "source": [
        "### Export the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQgqGJ_1m2Vu"
      },
      "source": [
        "# Export model so we can use it for other things\n",
        "# Note - this kills the model \n",
        "#TODO find better naming convention \n",
        "new_model = \"mrghg_230221_resnet34\"\n",
        "learn.export(f\"{c.model_dir}/{new_model}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u64mZBSinfzo"
      },
      "source": [
        "# Import model and test to see if it hasn't broken in the export process.\n",
        "imported_learner = load_learner(f\"{c.model_dir}/{c.model_name}.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "fGYG53Pa_Qog",
        "outputId": "5b43d07e-c6b0-4742-9bde-5917c9e9dcdf"
      },
      "source": [
        "# Predict from imported learner\n",
        "imported_learner.predict(f\"{c.png_dir}/-0.73212695655741_51.2533785354393.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3.3061301708221436,\n",
              "  6.372119903564453,\n",
              "  5.765547275543213,\n",
              "  1.3745146989822388,\n",
              "  3.039674997329712,\n",
              "  1.802012324333191),\n",
              " tensor([3.3061, 6.3721, 5.7655, 1.3745, 3.0397, 1.8020]),\n",
              " tensor([3.3061, 6.3721, 5.7655, 1.3745, 3.0397, 1.8020]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7193vyLfVy"
      },
      "source": [
        "#### Notes on Image Predictions\n",
        "\n",
        "A lower learning rate appears to cause slower training with more sophisticated conclusions. Sophistication also appears to arise from a deeper network, but I'm hitting a wall at roughly 0.6 rmse.\n",
        "\n",
        "---\n",
        "\n",
        "Currently, the networks are having some trouble defining more subtle characteristics of the images, which shows some flaws in my work. The network will need some supplemental information to accurately predict the greenhouse gas at this point. This may include the following:\n",
        "- **Latitude/Longitude.** Geography may affect predictions - all the images in my current dataset are near London, meaning they have far more greenhouse gases than most places. To encode a knowledge of city geography into a neural net may take some work...\n",
        "- **Property Value.** How valuable is this land? This could go some way to encoding city dynamics, as well as explaining where the land might be. If land is rural, but valuable, it's likely to be near major cities or airports. \n",
        "- **Nearby GHG Values.** Combined with wind direction, an understanding of source & direction of airflow may describe how areas inherit ghg's from elsewhere. An example of this would be the high concentration of NO<sub>2</sub> north of Heathrow Airport, which may be caused by common flight patterns heading north. \n",
        "- **Wind Direction.** See above. \n",
        "- **Land Use.** Depending on detail, this may help alleviate the \"grey field/massive factory\" issue described in my log. By proving that certain areas are rural, residential, or industrial, we can limit errors based on inferring purely visual information. If we can specifically define what a large grey box is doing, we can also come to more developed conclusions about its purpose. A recycling center, an oil refinery, and a brewery may all look similar from above, but information about what they _are_ will limit a neural network getting confused. \n",
        "- **Population Density/Economic Output.** This will work in a similar way to property value, where we can predict human activity and its effects on greenhouse gases. Economic output may have a complex relationship to GHG emissions that cannot be easily represented, depending on the form of industry. For example, an eco-tourist attraction may rely on its low carbon footprint for survival, whereas a petrol station relies on high carbon ouput. \n",
        "- **Land Height**\n",
        "\n",
        "Effectively, this network recognises certain features of high-GHG land. Depending on sophistication, this may include airports, power plants, or other rare features, as well as recognising different types of wilderness or residential districts. This will be used to extract a feature set for a tabular recommender, which can then be used to find more accurate readings. "
      ]
    }
  ]
}